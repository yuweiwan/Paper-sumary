{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACL2020调研总结【持续更新】\n",
    "因调研方向原因，目前主要为序列，匹配，分类相关，未包含文本生成，阅读理解，对话系统等内容。<br>\n",
    "根据ACL博客，今年投递论文的情况如下图：<br>\n",
    "结合前几年的动向可知，基本上segmentation, POS tagging等低级任务逐渐减少，而对话，生成等高级任务逐渐增多。信息提取一直是重点，而机器学习类型稳步增长，直到今年的第一（越来越多基于多任务评估的通用模型论文）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/qushi.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 小样本/自监督/无监督/弱监督\n",
    "过去两年间，可以看到研究趋势正转向在无标注文本上以自监督方式进行预训练，然后使用（潜在的）更小的特定于任务的数据集进行微调。本届会议上，很多论文研究如何在训练模型时使用更少的监督。这里有一些不是在大数据集上训练的方法及论文例子：\n",
    "无监督：Yadav et al. 提出了一种基于检索的问答方法，该方法可以迭代式地基于一个数据库来优化查询，从而检索用于回答特定问题的证据。Tamborrino et al. 通过使用一种掩码式语言模型为每个候选答案计算一个可信度分数，在常识多选题任务上得到了出色的结果。\n",
    "数据增强：Fabbri et al. 提出了一种用于自动化生成用于训练问答模型的 (上下文，问题，答案）三元组的方法。他们检索了与原始数据集中的上下文类似的上下文，然后生成 yes/no 以及模板化的 WH 问题（即 what/when/where/who 等），之后再在合成的三元组上训练模型。Jacob Andreas 提出使用在相似上下文中更常见的短语来替代罕见短语，从而提升神经网络的组成泛化性能。\n",
    "元学习：Yu et al. 使用了元学习来将用于上下文检测的知识从高资源语言迁移到低资源语言。\n",
    "主动学习：Li et al. 为共指消解任务开发一种高效的标注框架，其可通过主动学习来选择最有价值的样本进行标注。\n",
    "### 数据不平衡/数据增强/数据选择\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
